{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "**Before running this notebook, start TensorBoard in your terminal:**\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir logs/fit\n",
    "```\n",
    "\n",
    "Then open: **http://localhost:6006** in your browser\n",
    "\n",
    "TensorBoard will show training metrics as you run the cells below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard Introduction - Fashion-MNIST Classification\n",
    "# University at Buffalo - Neural Networks Lab\n",
    "\n",
    "In this lab, you'll train a fully connected neural network and use TensorBoard to visualize how different learning rates affect training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 23:30:28.374687: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-03 23:30:28.377688: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-03 23:30:28.387396: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-03 23:30:28.405729: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-03 23:30:28.405770: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-03 23:30:28.418589: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-03 23:30:29.336668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import datetime\n",
    "\n",
    "print(\"Imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Load and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Fashion-MNIST: 70,000 grayscale images of 10 clothing categories\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Flatten images from 28x28 to 784-dimensional vectors\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "# Class names for reference\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(f\"Training samples: {x_train.shape[0]}\")\n",
    "print(f\"Test samples: {x_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"Create a simple fully connected neural network.\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Set Up TensorBoard\n",
    "\n",
    "**EXPERIMENT: Change the learning rate below and observe how it affects training!**  \n",
    "Try values like: 0.1, 0.01, 0.001, 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logs will be saved to: logs/fit/20251203-233506_lr0.0001\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Create a unique log directory for this run\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + f\"_lr{LEARNING_RATE}\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,  # Log weight histograms every epoch\n",
    "    write_graph=True   # Log the model graph\n",
    ")\n",
    "\n",
    "print(f\"TensorBoard logs will be saved to: {log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: Compile and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with learning rate: 0.0001\n",
      "----------------------------------------\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 23:35:09.065476: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150528000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7147 - loss: 0.8905 - val_accuracy: 0.8066 - val_loss: 0.5746\n",
      "Epoch 2/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8258 - loss: 0.5188 - val_accuracy: 0.8331 - val_loss: 0.4870\n",
      "Epoch 3/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8421 - loss: 0.4598 - val_accuracy: 0.8421 - val_loss: 0.4474\n",
      "Epoch 4/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.4296 - val_accuracy: 0.8478 - val_loss: 0.4331\n",
      "Epoch 5/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8585 - loss: 0.4077 - val_accuracy: 0.8593 - val_loss: 0.4080\n",
      "Epoch 6/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8643 - loss: 0.3917 - val_accuracy: 0.8594 - val_loss: 0.3983\n",
      "Epoch 7/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8668 - loss: 0.3793 - val_accuracy: 0.8636 - val_loss: 0.3907\n",
      "Epoch 8/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8709 - loss: 0.3685 - val_accuracy: 0.8652 - val_loss: 0.3820\n",
      "Epoch 9/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8745 - loss: 0.3594 - val_accuracy: 0.8660 - val_loss: 0.3781\n",
      "Epoch 10/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8779 - loss: 0.3499 - val_accuracy: 0.8686 - val_loss: 0.3688\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining with learning rate: {LEARNING_RATE}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.8613\n",
      "Test Loss: 0.3927\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's Never Too Late to Launch TensorBoard!\n",
    "\n",
    "If you haven't started TensorBoard yet, run this command in your terminal:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir logs/fit\n",
    "```\n",
    "\n",
    "Then open your browser to: **http://localhost:6006**\n",
    "\n",
    "Your training data is already saved - TensorBoard will show all your previous runs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Tasks\n",
    "\n",
    "1. Run this notebook with the default learning rate (0.01)\n",
    "2. Launch TensorBoard and observe the loss/accuracy curves\n",
    "3. Change `LEARNING_RATE` to 0.1 and run again\n",
    "4. Change `LEARNING_RATE` to 0.0001 and run again\n",
    "5. Compare all three runs in TensorBoard\n",
    "\n",
    "### Questions to Answer:\n",
    "- Which learning rate converges fastest?\n",
    "- Which learning rate achieves the best final accuracy?\n",
    "- Do any learning rates show signs of instability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Learning Rate that converges the fastest is .001 at 21.18 seconds\n",
    "\n",
    "The Learning Rate that achieves the best final accuracy is is .001 at .9088 training accuracy and .8847 validation accuracy.\n",
    "\n",
    "Learning Rate .1 shows a lot of instability with a final accuracy under 20 percent which is very unstable. Also for .1 learning rate the epoch loss increased over time instead of decreasing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
